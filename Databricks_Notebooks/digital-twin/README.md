## What is a Digital Twin?

A Digital Twin is a virtual representation of a physical product (asset/equipment twin) or  process (process twin), used to understand and predict the physical counterpart’s performance characteristics

It is used throughout the product lifecycle to simulate, predict, and optimize the product and production system, before optimizing the physical assets or processes, continuously updated using real-world data.

Digital Twins drive advanced, value-adding use cases. Consider the following scenarios:
* A refinery’s crude distillation unit wants to shift fuel blends in one period and a different blend in the next period. Digital twins enable the company to simulate the changes and settings before they enact physical changes.  
* A company wants to reconfigure a line in a plant. It costs $200,000 per hour for a line to be down. Digital twins enable the company to test various new configurations of the line virtually before taking the line down.  
* An airplane engine manufacturer wants to determine when an engine needs to be serviced to ensure optimal performance and safety. They’re accountable to the airlines for on-time metrics, so any unplanned maintenance carries severe financial penalties. Digital twins are used to predict potential failure of components, and enable the maintenance crews to schedule maintenance.  
<br>  

## Scenario - Digital Twins for EV Battery Manufacturing Plants  

In this demo, we’ll create an EV Battery Manufactoring plant using Azure Digital Twins, with data and insights generated by Databricks:

- Model a part of the manufacturing process using Azure Digital Twins
- Demonstrate Databricks’ ingestion capabilities to efficiently and continuously process IoT data
- Leverage Databricks to showcase 2 common uses for digital twins in manufacturing:
  - **Predictive Maintenance**
  - **Root Cause Analysis & Troubleshooting**

___

&copy; 2022 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the Databricks License [https://databricks.com/db-license-source].  All included or referenced third party libraries are subject to the licenses set forth below.

To run this accelerator, clone this repo into a Databricks workspace. Attach the RUNME notebook to any cluster running a DBR 11.0 or later runtime, and execute the notebook via Run-All. A multi-step-job describing the accelerator pipeline will be created, and the link will be provided. Execute the multi-step-job to see how the pipeline runs.

The job configuration is written in the RUNME notebook in json format. The cost associated with running the accelerator is the user's responsibility.
