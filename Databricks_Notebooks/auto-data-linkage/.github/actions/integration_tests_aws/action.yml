name: run integration tests
description: runs linking and dedupe tests on AWS
inputs:
  deployment_token:
    description: "Databricks PAT for running test"

runs:
  using: "composite"
  steps:
    - name: Run AWS test
      uses: databricks/run-notebook@v0
      with:
        local-notebook-path: integration-tests/RUN_TESTS.py
        git-commit: ${{ github.event.pull_request.head.sha }}
        databricks-host: https://e2-demo-west.cloud.databricks.com
        databricks-token: ${{ inputs.deployment_token }}
        new-cluster-json: >
          {
            "num_workers": 0,
            "spark_version": "11.3.x-cpu-ml-scala2.12",
            "data_security_mode": "SINGLE_USER",
            "node_type_id": "i3.xlarge",
            "aws_attributes": {
                "availability": "ON_DEMAND"
             },
            "spark_conf": {
                 "spark.master": "local[*, 4]",
                 "spark.databricks.cluster.profile": "singleNode"
             },
             "custom_tags": {
                 "ResourceClass": "SingleNode"
             }
          }
        notebook-params-json: >
          {
            "run_job": "True"
          }
        access-control-list-json: >
          [
            {
              "group_name": "users",
              "permission_level": "CAN_VIEW"
            }
          ]
