name: run integration tests
description: runs linking and dedupe tests on GCP
inputs:
  deployment_token:
    description: "Databricks PAT for running test"

runs:
  using: "composite"
  steps:
    - name: Run GCP tests
      uses: databricks/run-notebook@v0
      with:
        local-notebook-path: integration-tests/RUN_TESTS.py
        git-commit: ${{ github.event.pull_request.head.sha }}
        databricks-host: https://416411475796958.8.gcp.databricks.com
        databricks-token: ${{ inputs.deployment_token }}
        new-cluster-json: >
          {
             "num_workers": 0,
             "spark_version": "11.3.x-cpu-ml-scala2.12",
             "data_security_mode": "SINGLE_USER",
             "node_type_id": "n1-highmem-4",
             "gcp_attributes": {
               "availability": "ON_DEMAND_GCP"
             },
             "spark_conf": {
                 "spark.master": "local[*, 4]",
                 "spark.databricks.cluster.profile": "singleNode"
             },
             "custom_tags": {
                 "ResourceClass": "SingleNode"
             }
           }
        notebook-params-json: >
          {
           "run_job": "True"
          }
        access-control-list-json: >
          [
            {
              "group_name": "users",
              "permission_level": "CAN_VIEW"
            }
          ]